<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="gQIR">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>gQIR</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9DNREV2SQ0"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="icon" type="image/png" href=".static/images/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/svg+xml" href=".static/images/favicon.svg" />
  <link rel="shortcut icon" href=".static/images/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href=".static/images/apple-touch-icon.png" />
  <link rel="manifest" href=".static/images/site.webmanifest" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://aryan-garg.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://aryan-garg.github.io/hdrsplat/">
            HDRSplat
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">gQIR: Generative Quanta Image Reconstruction</h1>
          <h4 class="subtitle is-3">CVPR 2026</h4>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://aryan-garg.github.io">Aryan Garg</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://sizhuoma.netlify.app/">Sizhuo Ma</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://wisionlab.com/people/mohit-gupta/">Mohit Gupta</a>,
            </span>
          </div>

          <div class="is-size-3 publication-authors">
            <span class="author-block">University of Wisconsin-Madison<sup>1</sup>, Snap Inc.<sup>2</sup></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2602.20417"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=".static/supplementary/gQIR_supplementary.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-file-pdf"></i>
                  </span>
                  <span>Supplementary</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/_ao7yBxgpec"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <span class="link-block">
                <a href="todo_hf_demo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab"></i>
                  </span>
                  <span>ðŸ¤— Demo</span>
                  </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Aryan-Garg/gQIR"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- eXtreme Deformable Dataset. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/aRy4n/eXtreme-Deformable"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>eXtreme Deformable Dataset</span>
                  </a>
              </span>
                <span class="link-block">
                <a href="https://huggingface.co/datasets/aRy4n/real-color-SPAD-indoor6"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Real Color SPAD Dataset</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/supplementary/HDRSplat_Supplementary_Movie.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">gQIR</span> brings binary photon cubes from color SPADs to life.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/supplementary/Parkstatue_slide/Ours_parkstatue.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/supplementary/Stove_slide/Ours_stove.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/supplementary/CandleFiat_slide/Ours_CF.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/supplementary/Compare_Garden_Lights.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/supplementary/Compare_Candle_Fiat.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/supplementary/Compare_Park_Statue.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/supplementary/Compare_Stove.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div> -->
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Capturing high-quality images from only a few detected photons is a fundamental challenge in computational imaging. 
            Single-photon avalanche diode (SPAD) sensors promise high-quality imaging in regimes where conventional cameras fail, but raw <emph>quanta frames</emph> contain only sparse, noisy, binary photon detections. 
            Recovering a coherent image from a burst of such frames requires handling alignment, denoising, and demosaicing (for color) under noise statistics far outside those assumed by standard restoration pipelines or modern generative models. 
            We present an approach that adapts large text-to-image latent diffusion models to the photon-limited domain of quanta burst imaging. 
            Our method leverages the structural and semantic priors of internet-scale diffusion models while introducing mechanisms to handle Bernoulli photon statistics. 
            By integrating latent-space restoration with burst-level spatio-temporal reasoning, our approach produces reconstructions that are both photometrically faithful and perceptually pleasing, even under high-speed motion. 
            We evaluate the method on synthetic benchmarks and new real-world datasets, including the <b>first color SPAD burst dataset</b> and a challenging <b>eXtreme Deformable (XD) video benchmark</b>. 
            Across all settings, the approach substantially improves perceptual quality over classical and modern learning-based baselines, demonstrating the promise of adapting large generative priors to extreme photon-limited sensing.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
 
      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Extreme Motion Imaging Unlocked!</h2>
          <p>
            gQIR enables high perceptually quality and plausibility of reconstructions under extreme motion!
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/supplementary/NVS_depths/depth_CandleFiat_vitB.mp4"
                        type="video/mp4">
          </video>
        </div>

                <!-- <div class="item item-depth">
                  <video id="depth" autoplay controls muted loop playsinline height="100%">
                    <source src="./static/supplementary/NVS_depths/depth_SharpShadow_vitB.mp4"
                        type="video/mp4">
                  </video>
                </div> -->
      </div>
    </div>
          
    <!--/ Visual Effects. -->
    <div class="columns is-centered">
      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">Prompts For Semantic Editing of Photons</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our base generative prior, we can also use natural language to guide reconstruction in ambiguous regions.
            </p>
            <img src="./static/supplementary/prompt_cool_feature.png"
                 class="tonemapping-image"
                 alt="Prompt Guided Semantic Photon Editing."/>
          </div>

        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column">
          <div class="content">
            <h2 class="title is-3">gQIR's Architecture</h2>
            <p>
              As shown, gQIR is built in 3 stages: a) <b>Simultaneous Pre-degradation Removal and SPAD-Alignment</b>, b) 
              Adversarial distillation of SD2.1-zsnr-L5 for <b>perceptual enhancement</b>, and c) <b>Burst extension</b> for higher fidelity using our hybrid-3D FusionViT
            </p>
            <div class="content has-text-centered">
              <img src="./static/supplementary/pipeline.png" alt="model_architecture" class="interpolation-image">
            </div>
          </div>
        </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        
        <!--/ Re-rendering. -->

      <!-- </div>
    </div> -->
    <!--/ Animation. -->


    <!-- Concurrent Work.  NONE for gQIR -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Concurrent Work</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2405.15125">HDR-GS</a> also introduces HDR space 3D reconstructions.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2406.06216">LE3D</a> uses a color-MLP explicitly unlike ours to represent RAW color space.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @InProceedings{garg_2026_gqir,
        author    = {Garg, Aryan and Ma, Sizhuo and  Gupta, Mohit},
        title     = {gQIR: Generative Quanta Image Reconstruction},
        booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
        month     = {June},
        year      = {2026},
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/3dgs_night.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/Aryan-Garg" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website Template Credits: Nerfies <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
